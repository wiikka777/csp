{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e9597-0930-4ac3-aba5-1c2ac5827472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchfm.layer import FeaturesEmbedding, CrossNetwork, MultiLayerPerceptron\n",
    "\n",
    "class My_DeepCrossNetworkModel(nn.Module):\n",
    "    \"\"\"\n",
    "    原始 DCN 模型\n",
    "    \"\"\"\n",
    "    def __init__(self, field_dims, embed_dim, num_layers, mlp_dims, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = FeaturesEmbedding(field_dims, embed_dim)\n",
    "        self.embed_output_dim = len(field_dims) * embed_dim\n",
    "        self.cn = CrossNetwork(self.embed_output_dim, num_layers)\n",
    "        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropout, output_layer=False)\n",
    "        self.linear = nn.Linear(mlp_dims[-1] + self.embed_output_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed_x = self.embedding(x).view(-1, self.embed_output_dim)\n",
    "        x_l1 = self.cn(embed_x)\n",
    "        h_l2 = self.mlp(embed_x)\n",
    "        return self.linear(torch.cat([x_l1, h_l2], dim=1)).squeeze(1)\n",
    "\n",
    "\n",
    "class My_DeepCrossNetworkModel_withCommentsRanking(nn.Module):\n",
    "    \"\"\"\n",
    "    (修正版)\n",
    "    支持 CPU embedding 字典传入, 但在初始化时一次性将 Tensors 移至 GPU。\n",
    "    在 forward 中执行快速、安全的 GPU-native 索引。\n",
    "    \n",
    "    text_embeddings = {\n",
    "        \"video_emb_tensor_cpu\": Tensor(Nv, D),\n",
    "        \"video_id2idx\": dict,\n",
    "        \"comment_emb_tensor_cpu\": Tensor(Nc, D),\n",
    "        \"comment_id2idx\": dict\n",
    "    }\n",
    "    \"\"\"\n",
    "    def __init__(self, field_dims, comments_dims, embed_dim, num_layers,\n",
    "                 mlp_dims, dropout, text_embeddings,\n",
    "                 attention_dim=64, nhead=5):\n",
    "        super().__init__()\n",
    "\n",
    "        # 基础 embedding\n",
    "        self.individual_embedding = FeaturesEmbedding(field_dims, embed_dim)\n",
    "        self.shared_embedding = FeaturesEmbedding([comments_dims], embed_dim)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # (关键修正!)\n",
    "        # 在模型初始化时, *一次性* 将嵌入表从 CPU 移到 GPU\n",
    "        # 你的 48GB VRAM 足够容纳它们\n",
    "        print(\"Moving embedding tables to GPU...\")\n",
    "        self.video_emb_gpu = text_embeddings[\"video_emb_tensor_cpu\"].cuda()\n",
    "        self.comment_emb_gpu = text_embeddings[\"comment_emb_tensor_cpu\"].cuda()\n",
    "        print(\"Embedding tables moved to GPU.\")\n",
    "        \n",
    "        # 映射表 (id -> index) 仍然保留在 CPU, 它们很小\n",
    "        self.video_id2idx = text_embeddings[\"video_id2idx\"]\n",
    "        self.comment_id2idx = text_embeddings[\"comment_id2idx\"]\n",
    "\n",
    "        # 获取嵌入维度 (从 GPU 张量)\n",
    "        self.text_embed_dim = self.video_emb_gpu.size(1)\n",
    "        self.text_dim_reducer = nn.Linear(self.text_embed_dim, embed_dim)\n",
    "        self.comment_dim_reducer = nn.Linear(self.text_embed_dim, embed_dim)\n",
    "\n",
    "        # DCN 输入维度\n",
    "        self.embed_output_dim = len(field_dims) * embed_dim + 6 * embed_dim + embed_dim\n",
    "        self.seq_len = len(field_dims) + 7\n",
    "\n",
    "        # DCN 主体\n",
    "        self.cn = CrossNetwork(self.embed_output_dim, num_layers)\n",
    "        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_dims, dropout, output_layer=False)\n",
    "        self.linear = nn.Linear(mlp_dims[-1] + self.embed_output_dim, 1)\n",
    "\n",
    "        # Multi-head attention\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=self.embed_dim, num_heads=nhead, dropout=dropout, batch_first=True)\n",
    "\n",
    "        # 评论打分模块\n",
    "        self.comment_score_linear = nn.Sequential(\n",
    "            nn.Linear(self.embed_output_dim, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 6),\n",
    "        )\n",
    "        self.comment_score_linear_ = nn.Sequential(\n",
    "            nn.Linear(self.embed_output_dim, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 6),\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.comment_probs = None\n",
    "        self.comment_probs_ = None\n",
    "\n",
    "    # (移除!) 不再需要慢速的 get_... 函数\n",
    "    # def get_video_embeddings(self, video_ids): ...\n",
    "    # def get_comment_embeddings(self, comment_ids): ...\n",
    "\n",
    "    # ---------------------- forward (已修正为快速版) ----------------------\n",
    "    def forward(self, x):\n",
    "        # x 是在 GPU 上的 batch\n",
    "        current_device = x.device\n",
    "        \n",
    "        # 1. 基础特征 (已在 GPU)\n",
    "        individual_embed_x = self.individual_embedding(x[:, :-6])\n",
    "        # shared_embed_x = self.shared_embedding(x[:, -6:]) # 这行似乎没用\n",
    "\n",
    "        # 2. (修正!) 快速、安全地在 GPU 上获取 Video Embeddings\n",
    "        video_ids_batch = x[:, -8] # (B)\n",
    "        # 在 CPU 上构建索引列表 (使用 .get() 避免 KeyError, 找不到则用 0)\n",
    "        idx_video = [self.video_id2idx.get(str(int(v.item())), 0) for v in video_ids_batch]\n",
    "        # 将 *索引* 移到 GPU\n",
    "        idx_video_tensor = torch.tensor(idx_video, dtype=torch.long, device=current_device)\n",
    "        # (快速!) 直接在 GPU 上索引 GPU 嵌入表\n",
    "        text_embeds = self.video_emb_gpu[idx_video_tensor]\n",
    "        text_embeds = self.text_dim_reducer(text_embeds) # (在 GPU 上降维)\n",
    "\n",
    "        # 3. (修正!) 快速、安全地在 GPU 上获取 Comment Embeddings\n",
    "        comment_ids_batch = x[:, -6:] # (B, 6)\n",
    "        B, K = comment_ids_batch.size()\n",
    "        # 在 CPU 上构建 2D 索引列表 (B x K)\n",
    "        idx_list_comment = [\n",
    "            [self.comment_id2idx.get(str(int(cid.item())), 0) for cid in row]\n",
    "            for row in comment_ids_batch\n",
    "        ]\n",
    "        # 将 *索引* 移到 GPU\n",
    "        idx_comment_tensor = torch.tensor(idx_list_comment, dtype=torch.long, device=current_device)\n",
    "        # (快速!) 直接在 GPU 上索引 GPU 嵌入表\n",
    "        comment_embeds = self.comment_emb_gpu[idx_comment_tensor]\n",
    "        comment_embeds = self.comment_dim_reducer(comment_embeds) # (在 GPU 上降维)\n",
    "\n",
    "        # --- 4. 组合与 DCN (和原来一样) ---\n",
    "        text_embeds = text_embeds.unsqueeze(1)\n",
    "        embed_x = torch.cat([individual_embed_x, text_embeds, comment_embeds], dim=1)\n",
    "        embed_x = embed_x.view(B, -1)\n",
    "\n",
    "        # Multihead attention\n",
    "        embed_x_attn, _ = self.multihead_attn(embed_x.view(B, self.seq_len, self.embed_dim),\n",
    "                                              embed_x.view(B, self.seq_len, self.embed_dim),\n",
    "                                              embed_x.view(B, self.seq_len, self.embed_dim))\n",
    "        embed_x = embed_x_attn.reshape(B, -1)\n",
    "\n",
    "        # DCN\n",
    "        x_l1 = self.cn(embed_x)\n",
    "        h_l2 = self.mlp(embed_x)\n",
    "        p = self.linear(torch.cat([x_l1, h_l2], dim=1)).squeeze(1)\n",
    "\n",
    "        # 评论打分\n",
    "        comment_scores = self.comment_score_linear(embed_x)\n",
    "        comment_scores_ = self.comment_score_linear_(embed_x)\n",
    "        self.comment_probs = self.softmax(comment_scores)\n",
    "        self.comment_probs_ = self.softmax(comment_scores_)\n",
    "\n",
    "        return p\n",
    "\n",
    "    def get_comment_probs(self):\n",
    "        return self.comment_probs\n",
    "\n",
    "    def get_comment_probs_(self):\n",
    "        return self.comment_probs_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
