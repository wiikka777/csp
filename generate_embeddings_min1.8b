import os
import torch
import pandas as pd
import csv
import json
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel # 确保 LoRA 加载

# ======================================================
# 1. 配置
# ======================================================
FINETUNED_MODEL_PATH = "finetune/Qwen1.8B_LCU_SFT"
BASE_MODEL = "Qwen/Qwen1.5-1.8B" 
VIDEO_METADATA_PATH = "LCU-main/rec_datasets/KuaiComt/photo_table_final.csv"
COMMENT_METADATA_PATH = "LCU-main/rec_datasets/KuaiComt/comment_table_final.csv"

# (修正!) 加载由脚本 1 生成的 ID 列表
REQUIRED_VIDEO_ID_PATH = "LCU-main/rec_datasets/WM_KuaiComt/REQUIRED_video_ids.json"
REQUIRED_COMMENT_ID_PATH = "LCU-main/rec_datasets/WM_KuaiComt/REQUIRED_comment_ids.json"

output_dir = "finetune/embeddings"
os.makedirs(output_dir, exist_ok=True)
device = "cuda"

VIDEO_ID_COL = 'photo_id'
VIDEO_TEXT_COL = 'caption'
COMMENT_ID_COL = 'comment_id' 
COMMENT_TEXT_COL = 'comment_content'

# ======================================================
# 2. 加载模型和 tokenizer (使用 LoRA)
# ======================================================
print(f"Loading base model: {BASE_MODEL}")
tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    BASE_MODEL,
    torch_dtype=torch.float16,
    device_map="auto",
    trust_remote_code=True
)
print(f"Loading LoRA adapter from: {FINETUNED_MODEL_PATH}")
model = PeftModel.from_pretrained(model, FINETUNED_MODEL_PATH)
model.eval()
print("LoRA adapter loaded.")


if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token
    model.config.pad_token_id = tokenizer.eos_token_id
print("Model and tokenizer loaded.\n")

# ======================================================
# 3. 加载必需的 ID
# ======================================================
print(f"Loading REQUIRED video IDs from {REQUIRED_VIDEO_ID_PATH}...")
with open(REQUIRED_VIDEO_ID_PATH, 'r') as f:
    # (关键修正!) 确保加载的 ID 都是整数 (int)
    required_video_ids = set(int(v) for v in json.load(f))
print(f"Loaded {len(required_video_ids)} required video IDs (short IDs).")

print(f"Loading REQUIRED comment IDs from {REQUIRED_COMMENT_ID_PATH}...")
with open(REQUIRED_COMMENT_ID_PATH, 'r') as f:
    required_comment_ids = set(int(v) for v in json.load(f)) 
print(f"Loaded {len(required_comment_ids)} required comment IDs (short IDs).")

# ======================================================
# 4. 嵌入生成函数 (已修正为 Last Token Pooling)
# ======================================================
def create_video_prompt(text):
    return f"Video Title: {str(text) if pd.notna(text) else ''}"

def create_comment_prompt(text):
    return f"Comment: {str(text) if pd.notna(text) else ''}"

def encode_text(text, prompt_func, max_len=128):
    prompt = prompt_func(text)
    inputs = tokenizer(
        prompt, 
        return_tensors="pt", 
        truncation=True, 
        max_length=max_len, 
        padding=True 
    ).to(device)

    with torch.no_grad():
        try:
             outputs = model(**inputs, output_hidden_states=True)
             hidden = outputs.hidden_states[-1]
        except TypeError:
             hidden = model.transformer(**inputs).last_hidden_state

    mask = inputs['attention_mask']
    last_token_idx = mask.sum(dim=1) - 1
    
    if last_token_idx.item() < 0:
        hidden_size = model.config.hidden_size
        return torch.zeros(hidden_size).cpu()

    embedding = hidden[0, last_token_idx.item(), :] 
    return embedding.cpu()

# ======================================================
# 5. 生成视频嵌入 (已修正! 使用 "短 ID = 行号" 假设)
# ======================================================
video_embeddings = {}
print("Generating video embeddings...")
# (修正!) 读取 video_table_final.csv (TSV, \t)
video_df = pd.read_csv(
    VIDEO_METADATA_PATH, 
    sep='\t',
    usecols=[VIDEO_TEXT_COL], # (修正!) 我们只按行号索引, 只需要文本列
    engine='python', 
    on_bad_lines='skip',
    dtype={VIDEO_TEXT_COL: str}
)
print(f"Loaded {len(video_df)} total videos from video_table_final.")

# (关键!) 过滤出在 video_df 范围内的 "短 ID"
# (修正!) 现在的 idx 是 int, 比较可以正常进行
valid_short_video_ids = [idx for idx in required_video_ids if 0 <= idx < len(video_df)]
print(f"Found {len(valid_short_video_ids)} videos to embed (using short ID as row index).")

for short_id in tqdm(valid_short_video_ids, desc="Processing videos"):
    # (关键!) 使用 "短 ID" 作为行号 (iloc)
    text = video_df.iloc[short_id][VIDEO_TEXT_COL]
    
    # (关键!) 保存时, 键(key) 必须是 "短 ID"
    video_embeddings[short_id] = encode_text(text, create_video_prompt)

save_path_video = os.path.join(output_dir, "video_embeddings_qwen1.8b_tiny.pt")
torch.save(video_embeddings, save_path_video)
print(f"\n✅ Video embeddings saved at {save_path_video} (Total: {len(video_embeddings)})")

# ======================================================
# 6. 生成评论嵌入 (使用 "短 ID = 行号" 假设)
# ======================================================
comment_embeddings = {}
print("\nGenerating comment embeddings...")
# (修正!) 读取 comment_table_final.csv (TSV, \t)
comment_df = pd.read_csv(
    COMMENT_METADATA_PATH, 
    sep='\t',
    usecols=[COMMENT_TEXT_COL], # (修正!) 我们只按行号索引, 只需要文本列
    engine='python', 
    on_bad_lines='skip',
    dtype={COMMENT_TEXT_COL: str}
)
print(f"Loaded {len(comment_df)} total comments from comment_table_final.")

# (关键!) 过滤出在 comment_df 范围内的 "短 ID"
# (修正!) 现在的 idx 是 int, 比较可以正常进行
valid_short_ids = [idx for idx in required_comment_ids if 0 <= idx < len(comment_df)]
print(f"Found {len(valid_short_ids)} comments to embed (using short ID as row index).")

for short_id in tqdm(valid_short_ids, desc="Processing comments"):
    # (关键!) 使用 "短 ID" 作为行号 (iloc)
    text = comment_df.iloc[short_id][COMMENT_TEXT_COL]
    
    # (关键!) 保存时, 键(key) 必须是 "短 ID"
    comment_embeddings[short_id] = encode_text(text, create_comment_prompt)

save_path_comment = os.path.join(output_dir, "comment_embeddings_qwen1.8b_tiny.pt")
torch.save(comment_embeddings, save_path_comment)
print(f"\n✅ Comment embeddings saved at {save_path_comment} (Total: {len(comment_embeddings)})")
